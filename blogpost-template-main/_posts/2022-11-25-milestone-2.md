## 1 - Feature Engineering I

### a) Histogram of shot counts (goals and no-goals separated), binned by distance
![2-111111111](assets/1.png)
The histogram above shows shots vs goals distribution over the distance from the net. Each bar covers 10 meters, and the height indicates the number of shots/goals in each distance range. We can see that the largest shots/goals were in the 5-15 meters range. There’s also a smaller hill whose peak for shots at 35-45 meter range.
### b) Histogram of shot counts (goals and no-goals separated), binned by angle
![2-1111111211](assets/2.png)
This time, the histogram shows shots vs goals distribution over the angle from the net. Each bar covers 10 degress, and the height indicates the number of shots/goals in each distance range. We can see that the largest shots were in the 25-35 degress range. and the largest goals at 5-15 degrees.
### c) Histogram where one axis is the distance and the other is the angle
![2-1111113111](assets/3.png)
![2-1111111411](assets/4.png)
![2-11111411411](assets/5.png)

A Jointplot comprises three plots. Out of the three, one plot displays a graph which shows how the angle from the net varies with the distance from the net

The above plot displays a scatterplot with two histograms at the margins of the graph. If we observe the scatterplot, there seems to be a negative relationship between the columns distance from the net and angle from the net.
We can also observe that we have an important concentrations of goals with small values of distance and angles.
Most values are concentrated around the left bottom side which means most shots and goals are shot from a near distance from the net.
Outliers are the data points that lie far away from the rest of the data values, in the graph we can see outliers 2 clusters of outliers as well as in the histograms.

### a) Plot of goal rate vs distance of shot :
![2-11111116411](assets/6.png)
From the plot above, we can notice that the goal ratio is about 20% when we are at a small distance (less than 10 meters) from the net. The goal ratio decreases when we start going far from the net. We can see that the smallest value is achieved when the distance is between 40 and 80 i.e. when we are far from the net. We can also notice that the goal ratio increases after the bin 80-90 i.e. when the shots are shot from the opposite rink side, we can consider these shots as outliers as they are events that occur rarely.
### b) Plot of angle rate vs distance of shot :
![2-11111117411](assets/7.png)
From the plot above, we can observe that the goal ratio is about 15% when we are in front of the net (less than 0-20 degrees) . The goal ratio decreases as we move away from the center of y. Qe can say that the worst angle to shoot from it is 50-80 and the best angle to obtain a goal is 0-20. We can also notice that the goal ratio increases after the bin 80-90 i.e. when the shots are shot from above the net, we can consider these shots as outliers as they are events that occur rarely.
### c) Histogram of goals, binned by distance, with separate empty net and non-empty net events :
![2-11111118411](assets/8.png)
Non Empty net :
![2-11119111411](assets/9.png)

Empty net :
![2-111111111411](assets/10.png)
We can say that when the net is not empty, we have a better chance to goal when we shot from a distance between 7 and 15 and then our chances decreases. But when the net is empty, the chances increases for all kind of shots especially the ones in 10-20 meters

## 2 - Baseline Models

We use simple models like logistic regression to perform classification. We generated following
models:
### a) Using distance as feature:
We applied logistic regression with input feature as distance and output/label as is_goal.
We got the accuracy of 91% precision score 0.91 and Fscore 0.95. This means it can predict 91
out of 100 inputs correctly.
![1-1](assets/har11.png)
![1-2](assets/har12.png)
![1-3](assets/har13.png)
![1-4](assets/har14.png)

### b) Using angle as feature:
We applied logistic regression with input feature as angle and output/label as is_goal.
We got the accuracy of 91% precision score 0.91 and Fscore 0.95. This means it can predict 91
out of 100 inputs correctly.
![2-1](assets/har21.png)
![2-2](assets/har22.png)
![2-3](assets/har23.png)
![2-4](assets/har24.png)

### c) Using angle and distance as features:
We applied logistic regression with input feature as distance and output/label as is_goal.
We got the accuracy of 91% precision score 0.91 and Fscore 0.95. This means it can predict 91
out of 100 inputs correctly.

![3-1](assets/har31.png)
![3-2](assets/har32.png)
![3-3](assets/har33.png)
![3-4](assets/har34.png)

We quickly come to the conclusion that the logistic regression model consistently predicts goals,
regardless of the features used. It implies that a more sophisticated model must be taken into
account for this binary classification, which will be investigated in Tasks 5 and 6. We even
contrast the non-learning statistical method with the log-reg.
## 3 - Feature Engineering II
List of all of the features created for this section are :
- Y_net : the y  coordinates of the net of the opposing team
- X_net	: the x  coordinates of the net of the opposing team
- last_EventType : the previous event type before a shot or goal was made.
- last_period : the period when the previous event occurred
- last_periodTime : the time when the previous event occurred
- last_eventxCoord : the x coordinate of the previous event
- last_eventyCoord : the y coordinate of the previous event
- last_shotType : the type of the previous event
- last_periodSeconds : the time in seconds of the previous event
- last_Distance_from_net : the distance from the net of the opposing team of the previous event
- last_Angle_from_net : the angle from the net of the opposing team of the previous event
- time_from_last_event : the time between the current shot/ goal and the the event that occurred before
- distance_from_last_event : the distance between the current goal/shot and the previous shot/event
- rebound : a flag that indicates if the previous event is a shot or not
- change_in_angle : the angle beween the previous event and the current shot/goal.
- speed : the speed of the events ( the distance from the previous event, divided by the time since the previous event.)

- Link to the experiment which stores the filtered DataFrame artifact for the specified game :
https://www.comet.com/yasmine/ift6758-a22-milestone-2/b6742c589a64401d843cb0766cbce801?assetId=0b219e7f221d4e7ca6bff8537d0834a2&assetPath=dataframes&experiment-tab=assets
## 4 - Advanced Models

### a) Question 1 :
![6-6](assets/megha1.png)

The baseline xgboost model is trained on the “Distance” and “Angle” features obtained post implementing feature engineering 1. The model is trained with a learning rate of 0.1, a maximum depth of 7 and the number of estimators are taken as 5000. The subsampling is set as 0.5 . The trained accuracy obtained through such a model is 0.7255 while the validation accuracy is 0.7144
 The validation set is 20% and the training set is 80% of the actual training set provided. The accuracy / prediction is much better using the xgboost as compared to the logistics regression baseline model.
![4-1](assets/megha11.png)
![4-2](assets/megha13.png)
![4-3](assets/megha14.png)
![4-4](assets/megha15.png)
![4-5](assets/megha16.png)

### b) Question 2 :
Post preprocessing the data to remove null values in the entire dataset and infinite values in the speed column, we tune the hyperparameters with the following parameters using Grid SearchCV.
learning_rate_list=[0.02,0.05,0.1]
max_depth_list =[5,7,10]
n_estimators_list = [2000, 3000,5000]

Below is the table obtained to get compare and rank the combination of characters that provide the highest accuracy.
![6-2](assets/megha2.png)

We further plot curves to infer the parameter that provide the highest accuracy.
The graphs are shown below:
![4-21](assets/megha21.png)


From the above figure, we can conclude that validation accuracy decreases as we increase the number of estimators and the depth of the tree for our data.
![4-22](assets/megha22.png)
We can conclude from the above figure that the validation accuracy decreases as we increase the learning rate.
The new tuned model is obtained by using the following parameters:
learning_rate=0.02,
max_depth=6,
n_estimators=2000,
subsample=1,colsample_bytree=1
The accuracy thus obtainedare :
AUC Train: 0.7268
AUC Valid: 0.6767
The new tuned model is trained on the data obtained from feature engineering 2 and thus have different features as from the baseline model. The accuracy is almost equal to or lower than the XGBoost baseline model.
![4-23](assets/megha23.png)

  train and validation AUC increases as no of trees increases
![4-24](assets/megha24.png)

The confusion matrix for the results of the tuned model.
Below is the Classification report of the tuned model:
![4-25](assets/megha25.png)
![4-26](assets/megha26.png)
![4-27](assets/megha27.png)
![4-28](assets/megha28.png)
![4-210](assets/megha210.png)
### c) Question 3 :
The importance of features is given by the below table:
![4-31](assets/megha31.png)
SHAP is used to keep a track of  the contribution of features in increasing or decreasing the performance of the model Here are some of the figures obtained through SHAP.
![4-32](assets/megha32.png)
![4-33](assets/megha33.png)
![4-34](assets/megha34.png)
![4-35](assets/megha35.png)
![4-36](assets/megha36.png)
![4-37](assets/megha37.png)
Features pushing the prediction higher are shown in red, those pushing the prediction lower are in blue.
The selected features from the above figures('time_from_last_event',,'speed','last_Angle_from_net','last_period','last_Distance_from_net'
) were fed to the XGBoost model and the validation accuracy thus obtained is validation_0-auc:0.63307
The model did not perform better than the XGBoost baseline and the XGboost tuned model with the full set of features. We can hence conclude that decreasing the features in the provided dataset did not increase the accuracy. And training the model on Distance and Angle performed better and gave the best results among Logistic Regression models and the XGBoost models.

## 5 - Give it your best shot!
In this part, we choose to work with Neural networks. below the methods used :
### a) EDA (Exploratory Data Analysis) :
We started by analyzing the missing values :
![5-51](assets/kh51.png)

More than 80% of the values are missing for some features, so we decided to drop these features.


In the figure below, we can see the correlation map between our features :
![5-52](assets/kh52.png)
There are no high correlation between our features, we can keep all of them for now.

We can do more feature engineering in this par.
### b) Feature engineering :
#### 1) Data encoding :
- the periodType contains 3 values : OVERTIME, REGULAR and SHOOTOUT, we decided to use a OneHotEncoder.
![5-53](assets/kh53.png)
- The second categorical feature is teamOfShooter, for this feature, we decided to use : LeaveOneOutEncoder because we have a nominal feature, with lot of teams and also to avoid overfitting
![5-54](assets/kh54.png)
- We have different shot type :
![5-50](assets/kh50.png)
- For our last categorical feature : shotType, we decided to use an OrdinalEncoder becasue the order matter here, as we saw in the previous milestone
![5-55](assets/kh55.png)

#### 2) Feature selection :
In this part, we used ExtraTreesClassifier as a feature selection method.
The feature selection is used to make the process more accurate. It also increases the prediction power of the models by selecting the most critical variables and eliminating the redundant and irrelevant ones.
![5-56](assets/kh56.png)
#### 3) Data standardization :
The goal of using data standardization is to bring down all the features to a common scale
without distorting the differences in the range of the values.
It will help training of our neural networks as the different features are on a similar scale and help it to converge faster.
#### 4) Imbalanced data :
From the plot below, we can see that our data is imbalanced. Thus, our model will always get high accuracy since if it predicts all the rows as class 0. To deal with this, we decided to use SMOTE method
- SMOTE works by selecting examples that are close in the feature space, drawing a line between the examples in the feature space and drawing a new sample at a point along that line.
![5-57](assets/kh57.png)
### b) Model training :
Below the metrics we choose to evaluate the model:

```python
METRICS = [
      keras.metrics.TruePositives(name='tp'),
      keras.metrics.FalsePositives(name='fp'),
      keras.metrics.TrueNegatives(name='tn'),
      keras.metrics.FalseNegatives(name='fn'),
      keras.metrics.BinaryAccuracy(name='accuracy'),
      keras.metrics.Precision(name='precision'),
      keras.metrics.Recall(name='recall'),
      keras.metrics.AUC(name='auc'),
      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve
]
```

We used the Sequential API to build the model


```python
# build a model
model = Sequential()
model.add(Dense(16, input_shape=(X.shape[1],), activation='relu')) # Add an input shape! (features,)
model.add(Dense(16, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.summary()

# compile the model
model.compile(optimizer='Adam',
              loss='binary_crossentropy',
              metrics=METRICS)

# early stopping callback
# This callback will stop the training when there is no improvement in
# the validation loss for 10 consecutive epochs.
es = EarlyStopping(monitor='val_accuracy',
                                   mode='max', # don't minimize the accuracy!
                                   patience=10,
                                   restore_best_weights=True)

# now we just update our model fit call
history = model.fit(X,
                    y,
                    callbacks=[es],
                    epochs=100,
                    batch_size=10,
                    validation_split=0.2,
                    shuffle=True,
                    verbose=1)
```

We also used an early stopping callback that will stop the training when there is no improvement in the validation loss for 10 consecutive epochs.
![5-58](assets/kh58.png)
### b) Results :
![5-61](assets/kh61.png)
![5-62](assets/kh62.png)
![5-63](assets/kh63.png)
![5-64](assets/kh64.png)
![5-65](assets/kh65.png)
![5-66](assets/kh66.png)
![5-67](assets/kh67.png)
![5-68](assets/kh68.png)

The neural network model given below was built on a 80% random sample of the shots and
goasl, and validated on the 20% held out. The model did not over fit the training dataset and was deemed appropriate.
Saving to comet-ml :
```python
# Create an experiment with your api key
comet_exp6 = Experiment(
    api_key="LgN3RhQfuVAcQnKyC9X0Gk1PC",
    project_name="ift6758-a22-milestone-2",
    workspace="yasmine",
    log_code=True,
)

# save the model to disk
filename = '../models/TryBestShot_bestmodel.sav'
pickle.dump(model, open(filename, 'wb'))
comet_exp6.log_model("Try best shot6", '../models/TryBestShot_bestmodel.sav')
comet_exp6.log_metric("accuracy", accuracy_score(y, preds))
#these will all get logged
params={'batch_size':10,
        'epochs':27,
        'layer_num':4,
        'optimizer':'adam',
        'patience':10
}
comet_exp6.log_parameters(params)

comet_exp6.log_dataframe_profile(
X,
name='df_smote',  # keep this name
dataframe_format='csv'  # ensure you set this flag!
)
```


links to experiments :
- https://www.comet.com/yasmine/ift6758-a22-milestone-2/355986f89fc74eb0b54d19099ae3c242?experiment-tab=chart&showOutliers=true&smoothing=0&transformY=smoothing&xAxis=wall
- https://www.comet.com/yasmine/ift6758-a22-milestone-2/21355c4d9aae4381adefa20db7738efe?experiment-tab=chart&showOutliers=true&smoothing=0&transformY=smoothing&xAxis=wall
- https://www.comet.com/yasmine/ift6758-a22-milestone-2/62e5259bcbe3444780c8f3ed8edb8577?experiment-tab=chart&showOutliers=true&smoothing=0&transformY=smoothing&xAxis=wall
- https://www.comet.com/yasmine/ift6758-a22-milestone-2/26f5adae91814c9795c79958404f710d?experiment-tab=chart&showOutliers=true&smoothing=0&transformY=smoothing&xAxis=wall
- https://www.comet.com/yasmine/ift6758-a22-milestone-2/5b6ecf5ce6c048a5b66d3e26d668198d?experiment-tab=chart&showOutliers=true&smoothing=0&transformY=smoothing&xAxis=wall
- https://www.comet.com/yasmine/ift6758-a22-milestone-2/76ff849af73a4310969ff68800e882d4?experiment-tab=chart&showOutliers=true&smoothing=0&transformY=smoothing&xAxis=wall
- https://www.comet.com/yasmine/ift6758-a22-milestone-2/650ae41436dd4ce5935da01d49d7e80d?experiment-tab=chart&showOutliers=true&smoothing=0&transformY=smoothing&xAxis=wall
## 6 - Evaluate on test set :
Baseline models :

![5-22224](assets/x22.png)
![5-62222](assets/x23.png)
![5-6223](assets/x24.png)
![5-6224](assets/x25.png)

Xgboost model :
![5-22e224](assets/x1.png)
![5-62e222](assets/x2.png)
![5e-62e23](assets/x3.png)
![5e-6224](assets/x4.png)

Neural network , regular season :
![5-2222444](assets/reg1.png)
![5-6222442](assets/reg2.png)
![5-622443](assets/reg3.png)
![5-624424](assets/reg4.png)
![5-624424](assets/reg5.png)
Neural network , playoffs season :
![5-2222444](assets/off1.png)
![5-6222442](assets/off2.png)
![5-622443](assets/off3.png)
![5-624424](assets/off4.png)
![5-624424](assets/off5.png)

- First, with an accuracy of 91% and a bias in goal prediction, logistic regression is not performing any better on the testing data than it did last year. The accuracy score for XGBoost is 71. Neural networks remain the top model. 
- We noticed that the neural network continues to perform better when tested with the playoff data for the 2019-2020 season. Even though XGBoost (the inferior contender in this testing data) has a greater accuracy of 71% compared to 91% for logistic regression, the latter is still consistently predicting "GOAL"
